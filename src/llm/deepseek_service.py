import requests
import json
import time
import logging
from dataclasses import dataclass
from typing import Optional, Dict, Any
from functools import wraps

logger = logging.getLogger(__name__)

@dataclass
class GenerationConfig:
    """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏"""
    temperature: float = 0.7
    top_p: float = 0.9
    top_k: int = 40
    num_ctx: int = 4096
    max_tokens: Optional[int] = None
    repeat_penalty: float = 1.1
    
    def to_dict(self) -> Dict[str, Any]:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ —Å–ª–æ–≤–∞—Ä—å –¥–ª—è API"""
        return {k: v for k, v in self.__dict__.items() if v is not None}

def retry_on_failure(max_retries: int = 3, delay: float = 1.0):
    """–î–µ–∫–æ—Ä–∞—Ç–æ—Ä –¥–ª—è retry logic —Å —ç–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–º backoff"""
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            last_exception = None
            
            for attempt in range(max_retries):
                try:
                    return func(*args, **kwargs)
                except (requests.RequestException, requests.Timeout) as e:
                    last_exception = e
                    if attempt < max_retries - 1:
                        wait_time = delay * (2 ** attempt)  # Exponential backoff
                        logger.warning(f"Attempt {attempt + 1} failed: {e}. Retrying in {wait_time}s...")
                        time.sleep(wait_time)
                    else:
                        logger.error(f"All {max_retries} attempts failed")
                except Exception as e:
                    # –ù–µ retry –¥–ª—è –¥—Ä—É–≥–∏—Ö —Ç–∏–ø–æ–≤ –æ—à–∏–±–æ–∫
                    logger.error(f"Non-retryable error: {e}")
                    raise
            
            raise last_exception
        return wrapper
    return decorator

class DeepSeekService:
    def __init__(self, 
                 model_name: str = "deepseek-r1:14b",
                 ollama_url: str = "http://localhost:11434",
                 config: Optional[GenerationConfig] = None,
                 timeout: int = 120,
                 max_retries: int = 3,
                 **kwargs):
        
        self.model_name = model_name
        self.ollama_url = ollama_url.rstrip('/')
        self.config = config or GenerationConfig()
        self.timeout = timeout
        self.max_retries = max_retries
        
        logger.info(f"Initializing DeepSeek service with model: {model_name}")
        
        try:
            self._validate_connection()
            logger.info("‚úì Ollama DeepSeek service ready")
        except Exception as e:
            logger.error(f"Failed to connect to Ollama: {e}")
            logger.info("Make sure Ollama is running: ollama serve")
            raise
    
    @retry_on_failure(max_retries=3, delay=2.0)
    def _validate_connection(self):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ Ollama —Å retry"""
        response = requests.get(f"{self.ollama_url}/api/tags", timeout=10)
        if response.status_code == 200:
            models = response.json().get('models', [])
            model_names = [m['name'] for m in models]
            
            if self.model_name in model_names:
                logger.info(f"‚úì Model {self.model_name} found in Ollama")
            else:
                logger.warning(f"Model {self.model_name} not found. Available: {model_names}")
                logger.info("Downloading model...")
                self._pull_model()
        else:
            raise requests.RequestException(f"Ollama not responding: {response.status_code}")
    
    def _pull_model(self) -> bool:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ–º"""
        try:
            response = requests.post(
                f"{self.ollama_url}/api/pull",
                json={"name": self.model_name},
                stream=True,
                timeout=300
            )
            
            for line in response.iter_lines():
                if line:
                    try:
                        data = json.loads(line)
                        status = data.get('status', '')
                        
                        if 'error' in data:
                            logger.error(f"Pull error: {data['error']}")
                            return False
                        
                        # –õ–æ–≥–∏—Ä—É–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å
                        if 'completed' in data and 'total' in data:
                            percent = (data['completed'] / data['total']) * 100
                            print(f"üì• Downloading: {percent:.1f}% - {status}")
                        elif status:
                            print(f"üì• Pull status: {status}")
                            
                    except json.JSONDecodeError:
                        continue
            
            return True
            
        except Exception as e:
            logger.error(f"Failed to pull model: {e}")
            return False
    
    @retry_on_failure(max_retries=3, delay=1.0)
    def generate(self, 
                 prompt: str, 
                 config: Optional[GenerationConfig] = None) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –∏ retry logic"""
        
        # –í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        if not prompt or not prompt.strip():
            raise ValueError("Prompt cannot be empty")
        
        generation_config = config or self.config
        start_time = time.time()
        
        payload = {
            "model": self.model_name,
            "prompt": prompt,
            "stream": False,
            "options": generation_config.to_dict()
        }
        
        print(f"ü§ñ Sending request to Ollama...")
        
        response = requests.post(
            f"{self.ollama_url}/api/generate",
            json=payload,
            timeout=self.timeout
        )
        
        if response.status_code == 200:
            result = response.json()
            raw_response = result.get("response", "")
            
            # –õ–æ–≥–∏—Ä—É–µ–º –º–µ—Ç—Ä–∏–∫–∏
            generation_time = time.time() - start_time
            prompt_tokens = result.get("prompt_eval_count", 0)
            completion_tokens = result.get("eval_count", 0)
            
            if prompt_tokens > 0 and completion_tokens > 0:
                tokens_per_sec = completion_tokens / generation_time if generation_time > 0 else 0
                print(f"üìä Generation: {completion_tokens} tokens in {generation_time:.2f}s ({tokens_per_sec:.1f} tok/s)")
            
            print(f"üì• Raw Ollama response: {raw_response[:500]}...")
            
            # –£–ª—É—á—à–µ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Ç–≤–µ—Ç–∞
            processed_response = self._process_response(raw_response)
            print(f"‚ú® Processed response: {processed_response[:200]}...")
            
            return processed_response
            
        else:
            error_msg = f"Ollama API error: {response.status_code} - {response.text}"
            logger.error(error_msg)
            raise requests.RequestException(error_msg)
    
    def _process_response(self, raw_response: str) -> str:
        """–£–ª—É—á—à–µ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞"""
        if not raw_response:
            return "‚ùì **–û—Ç–≤–µ—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω**"
        
        import re
        
        # –£–¥–∞–ª—è–µ–º –≤—Å–µ –≤–∏–¥—ã thinking —Ç–µ–≥–æ–≤ –±–æ–ª–µ–µ –Ω–∞–¥–µ–∂–Ω–æ
        thinking_patterns = [
            r'<think>.*?</think>',
            r'<thinking>.*?</thinking>',
            r'<reflection>.*?</reflection>',
            r'<\|thinking\|>.*?<\|/thinking\|>',
            r'<–≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ —Ä–∞–∑–º—ã—à–ª–µ–Ω–∏—è>.*?</–≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ —Ä–∞–∑–º—ã—à–ª–µ–Ω–∏—è>'
        ]
        
        clean_response = raw_response
        for pattern in thinking_patterns:
            clean_response = re.sub(pattern, '', clean_response, flags=re.DOTALL)
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π –æ—Ç–≤–µ—Ç —Å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º–∏
        answer_patterns = [
            (r'(?:–û—Ç–≤–µ—Ç|Answer):\s*(.*)', True),
            (r'(?:–ù–∞ –æ—Å–Ω–æ–≤–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤|Based on documents).*?:\s*(.*)', True),
            (r'(?:–ò—Å—Ö–æ–¥—è –∏–∑|Drawing from).*?:\s*(.*)', True),
            (r'(?:–í—ã–≤–æ–¥|Conclusion):\s*(.*)', True)
        ]
        
        extracted_answer = ""
        for pattern, use_group in answer_patterns:
            match = re.search(pattern, clean_response, re.DOTALL | re.IGNORECASE)
            if match and use_group:
                extracted_answer = match.group(1).strip()
                if extracted_answer and len(extracted_answer) > 10:
                    break
        
        # –ï—Å–ª–∏ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª–∏, –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ—á–∏—â–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
        if not extracted_answer:
            extracted_answer = clean_response.strip()
        
        # –§–∏–Ω–∞–ª—å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
        final_answer = self._format_answer(extracted_answer)
        
        return final_answer if final_answer else "‚ùå **–ù–µ —É–¥–∞–ª–æ—Å—å —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å –æ—Ç–≤–µ—Ç**"
    
    def _format_answer(self, answer: str) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ –¥–ª—è –∫—Ä–∞—Å–∏–≤–æ–≥–æ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
        if not answer:
            return ""
        
        import re
        
        # –£–¥–∞–ª—è–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –∏ –ø–µ—Ä–µ–Ω–æ—Å—ã
        answer = re.sub(r'\n{3,}', '\n\n', answer)
        answer = re.sub(r' {2,}', ' ', answer)
        answer = answer.strip()
        
        # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ –∞–±–∑–∞—Ü—ã
        paragraphs = [p.strip() for p in answer.split('\n') if p.strip()]
        
        formatted_parts = []
        
        for paragraph in paragraphs:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–Ω—ã–µ —Ç–∏–ø—ã –∫–æ–Ω—Ç–µ–Ω—Ç–∞
            if self._is_header(paragraph):
                formatted_parts.append(f"\n**{paragraph.rstrip(':')}:**\n")
            elif self._is_list_item(paragraph):
                clean_item = paragraph.strip('- ‚Ä¢*').strip()
                formatted_parts.append(f"‚Ä¢ {clean_item}")
            elif self._is_step(paragraph):
                formatted_parts.append(f"\n**{paragraph}**")
            else:
                # –û–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç
                formatted_parts.append(paragraph)
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º–∏ –æ—Ç—Å—Ç—É–ø–∞–º–∏
        result = '\n\n'.join(formatted_parts)
        result = re.sub(r'\n{3,}', '\n\n', result)
        
        return result.strip()
    
    def _is_header(self, text: str) -> bool:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –∑–∞–≥–æ–ª–æ–≤–∫–∏"""
        text_lower = text.lower()
        header_keywords = [
            '–∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è', '—à–∞–≥–∏', '–ø–æ—Ä—è–¥–æ–∫', '–∞–ª–≥–æ—Ä–∏—Ç–º', '–ø—Ä–æ—Ü–µ–¥—É—Ä–∞',
            '—Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è', '–Ω–∞—Å—Ç—Ä–æ–π–∫–∞', '–ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ', '—É—Å—Ç–∞–Ω–æ–≤–∫–∞', '–∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è'
        ]
        return (any(keyword in text_lower for keyword in header_keywords) 
                and len(text) < 100 
                and not text.lower().startswith(('–¥–ª—è', '—á—Ç–æ–±—ã', '–µ—Å–ª–∏')))
    
    def _is_list_item(self, text: str) -> bool:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —ç–ª–µ–º–µ–Ω—Ç—ã —Å–ø–∏—Å–∫–∞"""
        import re
        return bool(re.match(r'^[-‚Ä¢*]\s+', text.strip()) or 
                   re.match(r'^\d+\.\s+', text.strip()))
    
    def _is_step(self, text: str) -> bool:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —à–∞–≥–∏ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–π"""
        import re
        text_lower = text.lower().strip()
        step_patterns = [
            r'^\d+\.',  # 1. 2. 3.
            r'^—à–∞–≥ \d+',  # –®–∞–≥ 1
            r'^—ç—Ç–∞–ø \d+',  # –≠—Ç–∞–ø 1
            r'^—Å–Ω–∞—á–∞–ª–∞\b',  # –°–Ω–∞—á–∞–ª–∞
            r'^–∑–∞—Ç–µ–º\b',  # –ó–∞—Ç–µ–º  
            r'^–¥–∞–ª–µ–µ\b',  # –î–∞–ª–µ–µ
            r'^–ø–æ—Å–ª–µ —ç—Ç–æ–≥–æ\b',  # –ü–æ—Å–ª–µ —ç—Ç–æ–≥–æ
        ]
        return any(re.match(pattern, text_lower) for pattern in step_patterns)
    
    def create_rag_prompt(self, 
                         query: str, 
                         context: str, 
                         language: str = "russian",
                         style: str = "detailed",
                         max_context_length: int = 2000) -> str:
        """–£–ª—É—á—à–µ–Ω–Ω–æ–µ —Å–æ–∑–¥–∞–Ω–∏–µ RAG –ø—Ä–æ–º–ø—Ç–æ–≤ —Å —Ä–∞–∑–Ω—ã–º–∏ —Å—Ç–∏–ª—è–º–∏"""
        
        # –í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        if not query.strip():
            raise ValueError("Query cannot be empty")
        
        # –û–±—Ä–µ–∑–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –µ—Å–ª–∏ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π
        if len(context) > max_context_length:
            context = context[:max_context_length] + "..."
        
        if style == "detailed":
            return self._create_detailed_prompt(query, context, language)
        else:
            return self._create_concise_prompt(query, context, language)
    
    def _create_detailed_prompt(self, query: str, context: str, language: str) -> str:
        """–î–µ—Ç–∞–ª—å–Ω—ã–π –ø—Ä–æ–º–ø—Ç —Å –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è–º–∏"""
        
        if language.lower() == "russian":
            return f"""<thinking>
–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –∑–∞–¥–∞–ª –≤–æ–ø—Ä–æ—Å: {query}

–ú–Ω–µ –Ω—É–∂–Ω–æ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏ –¥–∞—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π, –ø–æ–ª–µ–∑–Ω—ã–π –æ—Ç–≤–µ—Ç –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ.

–ö–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤:
{context}

–Ø –¥–æ–ª–∂–µ–Ω –Ω–∞–π—Ç–∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏ –ø—Ä–µ–¥—Å—Ç–∞–≤–∏—Ç—å –µ—ë –≤ —É–¥–æ–±–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ.
</thinking>

–¢—ã - –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –ø–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –≤ –ö–∞–∑–∞—Ö—Å—Ç–∞–Ω–µ. –û—Ç–≤–µ—á–∞–π —Ç–æ—á–Ω–æ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞.

–ö–û–ù–¢–ï–ö–°–¢ –ò–ó –î–û–ö–£–ú–ï–ù–¢–û–í:
{context}

–í–û–ü–†–û–°: {query}

–¢–†–ï–ë–û–í–ê–ù–ò–Ø –ö –û–¢–í–ï–¢–£:
- –û—Ç–≤–µ—á–∞–π –¢–û–õ–¨–ö–û –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
- –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä—É–π –æ—Ç–≤–µ—Ç —Å –∑–∞–≥–æ–ª–æ–≤–∫–∞–º–∏ –∏ —Å–ø–∏—Å–∫–∞–º–∏
- –î–ª—è –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–π –∏—Å–ø–æ–ª—å–∑—É–π –ø–æ—à–∞–≥–æ–≤—ã–π —Ñ–æ—Ä–º–∞—Ç
- –í—ã–¥–µ–ª—è–π –≤–∞–∂–Ω—ã–µ –º–æ–º–µ–Ω—Ç—ã
- –ë—É–¥—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º –∏ –ø–æ–ª–µ–∑–Ω—ã–º

–û—Ç–≤–µ—Ç:"""
        
        else:
            return f"""<thinking>
User asked: {query}

I need to analyze the provided context and give a structured, helpful answer.

Context from documents:
{context}

I should find relevant information and present it in a useful format.
</thinking>

You are a corporate documentation assistant in Kazakhstan. Answer accurately based on the provided context.

CONTEXT FROM DOCUMENTS:
{context}

QUESTION: {query}

ANSWER REQUIREMENTS:
- Answer ONLY based on context
- Structure with headers and lists
- Use step-by-step format for instructions
- Highlight important points
- Be specific and helpful

Answer:"""
    
    def _create_concise_prompt(self, query: str, context: str, language: str) -> str:
        """–ö—Ä–∞—Ç–∫–∏–π –ø—Ä–æ–º–ø—Ç"""
        
        if language.lower() == "russian":
            return f"""<thinking>
–í–æ–ø—Ä–æ—Å: {query}
–ö–æ–Ω—Ç–µ–∫—Å—Ç: {context}
–ù—É–∂–µ–Ω –∫—Ä–∞—Ç–∫–∏–π —Ç–æ—á–Ω—ã–π –æ—Ç–≤–µ—Ç –Ω–∞ —Ä—É—Å—Å–∫–æ–º.
</thinking>

–ö–æ–Ω—Ç–µ–∫—Å—Ç: {context}

–í–æ–ø—Ä–æ—Å: {query}

–î–∞–π —Ç–æ—á–Ω—ã–π –∫—Ä–∞—Ç–∫–∏–π –æ—Ç–≤–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞:

–û—Ç–≤–µ—Ç:"""
        
        else:
            return f"""<thinking>
Question: {query}
Context: {context}
Need a concise accurate answer.
</thinking>

Context: {context}

Question: {query}

Provide a concise accurate answer based on context:

Answer:"""
